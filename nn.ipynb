{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24d2c93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c586b03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "test =pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a812fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head() # 28*28 images 784 pixels in input , rows = features , coloumn = batch size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "37b1841a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array (data)  #  converting pd frame into array\n",
    "test =np.array(test)\n",
    "m,n = data.shape  # m = batch size, n= feature map\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7fee3c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[0:int(0.8*m),:]\n",
    "val_data = data[int(0.8*m):m, :]\n",
    "\n",
    "X_train = train_data[:,1:].T #transpose for n,m shape\n",
    "\n",
    "X_train = X_train/255.0 # normalizing data \n",
    "Y_train = train_data[:,0] # extracting label of the data \n",
    "\n",
    "X_val = val_data[:, 1:].T\n",
    "X_val = X_val/255.0\n",
    "Y_val = val_data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "772c62e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33600,)\n",
      "(784, 33600)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(Y_train.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e976eca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(): #XAVIER initialization\n",
    "    W1 = np.random.randn(10,784) * np.sqrt(2/7840)  #do not include bias as input\n",
    "    B1 = np.random.randn(10,1) * np.sqrt(2/7840) #NO OF INPUT TO LAYER 1\n",
    "    W2 = np.random.randn(10,10) *np.sqrt(2/100)\n",
    "    B2 =np.random.randn(10,1)*np.sqrt(2/100)\n",
    "\n",
    "    return W1,B1,W2,B2\n",
    "\n",
    "def Batch_normalization(Y):\n",
    "\n",
    "    U = np.mean(Y,axis=0)\n",
    "    V  = np.var(Y,axis=0)\n",
    "    Y = (Y-U)/np.sqrt(V+.0000003)\n",
    "    return Y\n",
    "\n",
    "def relu(X):\n",
    "    return np.maximum(0,X)\n",
    "\n",
    "def Soft_max(Z):\n",
    "    # Z shape: (n_classes, m) -> softmax per sample (columns)\n",
    "    Z_shift = Z - np.max(Z, axis=0, keepdims=True)\n",
    "    expZ = np.exp(Z_shift)\n",
    "    return expZ / np.sum(expZ, axis=0, keepdims=True)\n",
    "\n",
    "\n",
    "def softmax(Z):\n",
    "    return np.exp(Z)/np.sum(np.exp(Z),axis =0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def one_hot_converter(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    return one_hot_Y.T\n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "def forward_propagation(W1,B1,W2,B2,X_train):\n",
    "\n",
    "    Z1 = W1.dot(X_train) + B1\n",
    "    #Z1 = Batch_normalization(Z1)\n",
    "    A1  = relu(Z1)\n",
    "    Z2 = W2.dot(A1) + B2\n",
    "    A2 = softmax(Z2)\n",
    "\n",
    "    return Z1,A1,Z2,A2\n",
    "\n",
    " \n",
    "def backward_propagation(W1, B1, W2, B2, Z1, A1, Z2, A2, X, Y):\n",
    "    m = X.shape[1]                            # use local batch size\n",
    "    one_hot_Y = one_hot_converter(Y)          # shape (n_classes, m)\n",
    "    dZ2 = A2 - one_hot_Y                      # (n_classes, m)\n",
    "    dW2 = (1.0 / m) * dZ2.dot(A1.T)\n",
    "    dB2 = (1.0 / m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = W2.T.dot(dZ2) * (Z1 > 0)            # ReLU derivative\n",
    "    dW1 = (1.0 / m) * dZ1.dot(X.T)\n",
    "    dB1 = (1.0 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    return dW1, dB1, dW2, dB2\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def update_parameters(W1,B1,W2,B2,dW1,dB1,dW2,dB2,learning_rate):\n",
    "\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    B1 = B1 -learning_rate *dB1\n",
    "    W2 = W2 -learning_rate* dW2\n",
    "    B2 = B2 -learning_rate*dB2\n",
    "\n",
    "    return W1,B1,W2,B2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_predictions(A2):\n",
    "  return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "  return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "\n",
    "\n",
    "def gradient_descent(X_train,Y_train,alpha,iterations):\n",
    "    W1,B1,W2,B2 = initialize_parameters()\n",
    "    for i in range(iterations):\n",
    "        Z1, A1, Z2, A2 = forward_propagation(W1,B1,W2,B2,X_train)\n",
    "        dW1,dB1,dW2,dB2 = backward_propagation(W1, B1, W2, B2, Z1, A1, Z2, A2, X_train, Y_train)\n",
    "        W1,B1,W2,B2 = update_parameters(W1,B1,W2,B2,dW1,dB1,dW2,dB2,alpha)\n",
    "        if (i%20) == 0:\n",
    "            print(\"iteration number\",i)\n",
    "            print(\"ACCURACY\",get_accuracy(get_predictions(A2),Y_train))\n",
    "    return W1,B1,W2,B2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcff6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "137dc07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number 0\n",
      "ACCURACY 0.10970238095238095\n",
      "iteration number 20\n",
      "ACCURACY 0.39863095238095236\n",
      "iteration number 40\n",
      "ACCURACY 0.5402678571428572\n",
      "iteration number 60\n",
      "ACCURACY 0.7139880952380953\n",
      "iteration number 80\n",
      "ACCURACY 0.791577380952381\n",
      "iteration number 100\n",
      "ACCURACY 0.815625\n",
      "iteration number 120\n",
      "ACCURACY 0.8335416666666666\n",
      "iteration number 140\n",
      "ACCURACY 0.8450892857142858\n",
      "iteration number 160\n",
      "ACCURACY 0.8555654761904762\n",
      "iteration number 180\n",
      "ACCURACY 0.8642559523809524\n",
      "iteration number 200\n",
      "ACCURACY 0.8710119047619047\n",
      "iteration number 220\n",
      "ACCURACY 0.8753273809523809\n",
      "iteration number 240\n",
      "ACCURACY 0.8786309523809523\n",
      "iteration number 260\n",
      "ACCURACY 0.8816071428571428\n",
      "iteration number 280\n",
      "ACCURACY 0.8836904761904761\n",
      "iteration number 300\n",
      "ACCURACY 0.8861607142857143\n",
      "iteration number 320\n",
      "ACCURACY 0.8884821428571429\n",
      "iteration number 340\n",
      "ACCURACY 0.8907142857142857\n",
      "iteration number 360\n",
      "ACCURACY 0.8917857142857143\n",
      "iteration number 380\n",
      "ACCURACY 0.892797619047619\n",
      "iteration number 400\n",
      "ACCURACY 0.8946428571428572\n",
      "iteration number 420\n",
      "ACCURACY 0.895922619047619\n",
      "iteration number 440\n",
      "ACCURACY 0.8978273809523809\n",
      "iteration number 460\n",
      "ACCURACY 0.8991369047619048\n",
      "iteration number 480\n",
      "ACCURACY 0.9005357142857143\n",
      "iteration number 500\n",
      "ACCURACY 0.9014583333333334\n",
      "iteration number 520\n",
      "ACCURACY 0.9024404761904762\n",
      "iteration number 540\n",
      "ACCURACY 0.9035416666666667\n",
      "iteration number 560\n",
      "ACCURACY 0.9044047619047619\n",
      "iteration number 580\n",
      "ACCURACY 0.905\n",
      "iteration number 600\n",
      "ACCURACY 0.9057440476190476\n",
      "iteration number 620\n",
      "ACCURACY 0.9063988095238096\n",
      "iteration number 640\n",
      "ACCURACY 0.907172619047619\n",
      "iteration number 660\n",
      "ACCURACY 0.9079166666666667\n",
      "iteration number 680\n",
      "ACCURACY 0.9082738095238095\n",
      "iteration number 700\n",
      "ACCURACY 0.909077380952381\n",
      "iteration number 720\n",
      "ACCURACY 0.9094047619047619\n",
      "iteration number 740\n",
      "ACCURACY 0.9100892857142857\n",
      "iteration number 760\n",
      "ACCURACY 0.9105952380952381\n",
      "iteration number 780\n",
      "ACCURACY 0.9114285714285715\n",
      "iteration number 800\n",
      "ACCURACY 0.9122023809523809\n",
      "iteration number 820\n",
      "ACCURACY 0.912797619047619\n",
      "iteration number 840\n",
      "ACCURACY 0.9134821428571429\n",
      "iteration number 860\n",
      "ACCURACY 0.9138392857142857\n",
      "iteration number 880\n",
      "ACCURACY 0.914702380952381\n",
      "iteration number 900\n",
      "ACCURACY 0.9152380952380952\n",
      "iteration number 920\n",
      "ACCURACY 0.9156547619047619\n",
      "iteration number 940\n",
      "ACCURACY 0.9161904761904762\n",
      "iteration number 960\n",
      "ACCURACY 0.9163392857142857\n",
      "iteration number 980\n",
      "ACCURACY 0.9167857142857143\n"
     ]
    }
   ],
   "source": [
    "W1,B1,W2,B2 = gradient_descent(X_train, Y_train, 0.1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "38ebbb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_label [3]\n",
      "actual_label 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_index =656\n",
    "Z1val, A1val,Z2val,A2val = forward_propagation(W1,B1,W2,B2,X_val[:,val_index,None])\n",
    "print(\"predicted_label\",get_predictions(A2val))\n",
    "print(\"actual_label\",Y_val[val_index])\n",
    "\n",
    "\n",
    "image_array = X_val[:,val_index].reshape(28,28)\n",
    "pyplot.imshow(image_array,cmap='gray')\n",
    "pyplot.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
